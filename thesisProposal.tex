% SIAM Article Template
\documentclass[onefignum,onetabnum]{siamart190516}

% Optional PDF information
\ifpdf
\hypersetup{
  pdftitle={Preconditioning Matrix-Free High-Order Finite Element Operators},
  pdfauthor={J. Thompson}
}
\fi

% Packages and macros go here
\usepackage{lipsum}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{algpseudocode} % Pseudo code and algorithms
\usepackage{subcaption}    % Subfigures
\ifpdf
  \DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}
\else
  \DeclareGraphicsExtensions{.eps}
\fi% Add a serial/Oxford comma by default.
\newcommand{\creflastconjunction}{, and~}

% Used for creating new theorem and remark environments
\newsiamremark{remark}{Remark}
\newsiamremark{hypothesis}{Hypothesis}
\crefname{hypothesis}{Hypothesis}{Hypotheses}
\newsiamthm{claim}{Claim}

% Sets running headers as well as PDF title and authors
\headers{Preconditioning Matrix-Free High-Order Finite Element Operators}{J. Thompson}

% Title. If the supplement option is on, then "Supplementary Material"
% is automatically inserted before the title.
\title{Preconditioning Matrix-Free High-Order Finite Element Operators}

% Authors: full names plus addresses.
\author{Jeremy L. Thompson\thanks{Department of Applied Mathematics, University of Colorado Boulder, Boulder, CO
  (\email{jeremy.thompson@colorado.edu}}
}

\usepackage{amsopn}
\DeclareMathOperator{\diag}{diag}

\begin{document}

\maketitle

% ------------------------------------------------------------------------------
% Abstract
% ------------------------------------------------------------------------------
\begin{abstract}
Finite element methods with global sparse matrices are not adequate for modeling solid mechanics problems at large scale.
We are particularly interested in efficient solvers for Neo-Hookean hyperelasticity at finite strain in the incompressible regime.
High-order matrix-free operators offer superior performance in comparison to assembled sparse matrices, both with respect to FLOPs needed for evaluation and the memory transfer needed for a matrix-vector product.
We describe a p-multigrid preconditioner that can be efficiently formulated with matrix-free operators.
Specifically, we discuss traditional smoothers such as Jacobi and Chebyshev as well as a new domain decomposition based smoother using Balancing Domain Decomposition by Constraints with subdomain solvers using approximate separable inverses based on the Fast Diagonalization Method.
With these techniques, we can solve substantially larger problems when compared to assembled global sparse matrices from low-order finite elements.
\end{abstract}

% ------------------------------------------------------------------------------
% Introduction
% ------------------------------------------------------------------------------
\section{Introduction}

Solid mechanics problems are commonly solved with finite element solvers using sparse matrix representations of low order finite elements.
However, assembled sparse matrices are memory bound for sufficiently large problems.
We explore using high-order finite elements implemented in a matrix-free fashion with appropriate preconditioners to solve solid mechanics problems at large scale.


High-order finite element methods offer advantages over low-order finite elements; $hp$ finite elements offer high accuracy and exponential convergence \cite{demkowicz1989toward}, \cite{oden1989toward}, \cite{rachowicz1989toward}.
However, high-order finite elements are less common because the operator or its Jacobian rapidly loses sparsity as the order is increased.
Matrix-free implementation of high-order finite elements can provide the benefits of high-order methods without relying upon matrix sparsity for efficient implementation.

High Performance Computing (HPC) hardware improvements in memory and network bandwidth have not kept up with improvements in Floating Point Operations per second (FLOPs), as highlighted in McCalpin's invited talk an Supercomputing 2016 \cite{mccalpin2016memory}.
Under these hardware constraints, matrix-free operators offer superior performance, both with respect to the memory transfer and FLOPs needed for needed for evaluation of a matrix-vector product.
However, iterative solvers are sensitive to the high condition numbers of high-order operator and require appropriate preconditioning to control total iterations and time to solution.

In Section \ref{hardware}, we discuss the specific hardware limitations that constrain the performance of HPC application codes.
In Section \ref{notation}, we provide notation to describe arbitrary PDEs and their Jacobians for matrix-free implementation.
In Section \ref{hyperelasticity}, we provide an overview of the solid mechanics problems we are exploring.
In Section \ref{preconditioning}, we discuss preconditioning techniques for these solid mechanics problems.

% ------------------------------------------------------------------------------
% Hardware Limitations
% ------------------------------------------------------------------------------
\section{Hardware Limitations}\label{hardware}

Two key performance metrics for HPC hardware are FLOPs and memory and network bandwidth.
FLOPs is the more widely popularized of these two metrics, but memory and network bandwidth is a common bottleneck in HPC application codes. 

The Top 500 \cite{meuertop500} list tracks the 500 supercomputers with the highest peak  FLOPs, as measured by High-Performance Linpack (HPL) \cite{petitethpl}.
HPL measures the performance when solving random dense linear systems in double precision via LU factorization and measures maximum achievable FLOPs.
Other benchmarks, such as High-Performance Geometric Multigrid (HPGMG) \cite{adams2014hpgmg} and High-Performance Conjugate Gradient (HPCG) \cite{dongarra2016high}, measure performance based upon solving a more complex benchmark problem.
The disparity between the FLOPs achieved in benchmarks such as HPGMG and HPCG and the peak FLOPs measured by HPL is partially explained by the growing gap between FLOPs and memory and network bandwidth.

Over the last thirty years, the peak FLOPs for new HPC hardware has been increasing more rapidly than memory bandwidth and network bandwidth, for both CPUs and GPUs.
As discussed in McCalpin's Supercomputing 2016 invited talk \cite{mccalpin2016memory}, peak FLOPs per socket have been increasing at a rate of 50-60\% per year while memory bandwidth has only been increasing at a rate of approximately 23\% per year and network bandwidth has only been increasing at a rate of approximately 20\% per year.
FLOPs have improved twice as much as memory and network bandwidth.
This problem is exacerbated by network latency, which is decreasing at a rate of approximately 20\% per year, and memory latency, which is \textit{increasing} at a rate of approximately 20\% per year.

\begin{figure}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=.99\linewidth]{img/peakFlopsAndBandwidth}
\caption{Peak FLOPs and Bandwidth}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\includegraphics[width=.99\linewidth]{img/peakRatio}
\caption{Ratio Bandwidth to FLOPs}
\end{subfigure}
\caption{System Balance}
\label{fig:peakratio}
\end{figure}

Using data from \cite{kruppcomparison}, we can see in Figure \ref{fig:peakratio} that AMD, NVIDIA, and Intel top of the line hardware has a steady decrease in the ratio of maximum memory bandwidth to FLOPs over the last 13 years.
HPC applications need to be careful to control the memory bandwidth required for their codes to better realize the FLOPs capabilities of HPC hardware.

% ------------------------------------------------------------------------------
% Matrix-Free Finite Elements
% ------------------------------------------------------------------------------
\section{Matrix-Free Finite Elements}\label{notation}

High-order finite elements implemented in a matrix-free fashion are one way to address the memory bandwith bottlenecks for modern HPC hardware.
In this section we develop notation to describe high-order matrix-free finite elements on unstructured meshes.
This notation is applicable to both linear and non-linear PDEs.

% -- Notation ------------------------------------------------------------------
\subsection{Notation}

The development of this notation will largely follow \cite{brown2010efficient}.

Let $\lbrace X_i \rbrace_{i = 1}^P$ denote the Legendre-Gauss-Lobatto (LGL) nodes of degree $P - 1$ on the reference interval $\left[ -1, 1 \right]$ while $\lbrace q_i \rbrace_{i = 1}^Q$ and $\lbrace w_i \rbrace_{i = 1}^Q$ denote the quadrature points and quadrature weights corresponding to a $Q$ point quadrature rule.
If we consider Lagrange basis functions $\lbrace \phi_i \rbrace_{i = 1}^P$, we can construct matrices $B_{i j} = \phi_j \left( q_i \right)$, $D_{i j} = \partial_x \phi_j \left( q_i \right)$, and $W_{i j} = w_i \delta_{i j}$, representing interpolation to the quadrature points, computation of derivatives at the quadrature points, and quadrature weights, respectively.

We can define the corresponding matrices for 3D problems via tensor products
\begin{equation}
\begin{array}{c}
\mathbf{B}   = B \otimes B \otimes B \hspace{5mm}
\mathbf{D}_0 = D \otimes B \otimes B\\
\mathbf{D}_1 = B \otimes D \otimes B \hspace{5mm}
\mathbf{D}_2 = B \otimes B \otimes D\\
\mathbf{W}   = W \otimes W \otimes W.
\end{array}
\label{basis_ops}
\end{equation}
The basis operations \ref{basis_ops} are defined on a reference element $\hat{K} = \left[ -1, 1 \right]^3$.
In the finite element and spectral element methods, we partition the domain $\Omega$ into a set of $E$ elements, denoted $\lbrace K^e \rbrace_{e = 1}^E$ with coordinate mapping to the reference element given by $X : \hat{K} \rightarrow K^e$.
The Jacobian of this mapping is given by $J_{i j} = \partial x_i / \partial X_j$, where $X$ is the reference coordinates and $x$ the physical coordinates.
We can invert the Jacobian and compute the derivatives of the physical coordinates in the reference space at every quadrature point.
\begin{equation}
\mathbf{D}_i^e = \Lambda \left( \frac{\partial X_0}{\partial x_i} \right) \mathbf{D}_0 + \Lambda \left( \frac{\partial X_1}{\partial x_i} \right) \mathbf{D}_1 + \Lambda \left( \frac{\partial X_2}{\partial x_i} \right) \mathbf{D}_2
\end{equation}
where $\Lambda \left( X \right)_{i j} = X_i \delta_{i j}$ expresses pointwise multiplication of $J_{i j}^{-1}$ at quadrature points as a diagonal matrix.
With this coordinate mapping, element integration weights become $\mathbf{W}^e = W \Lambda \left( \lvert J^e \left( q \right) \rvert \right)$.

When using an assembled matrix to represent a finite element operator, a global assembly operator is defined as $\mathcal{E} = \left[ \mathcal{E}^e \right]$, where $\mathcal{E}^e$ represents local restriction operators extracting degrees of freedom that correspond to element $e$ from the global solution vector.
Notice that these local restriction operators do not assume a structured mesh, a conforming mesh, or consistent polynomial order bases for each element.

With these definitions, we can represent the Galerkin system of equations corresponding to the weak form of arbitrary second order PDEs.
The weak form of PDEs is linear in test functions and can be expressed as pointwise operations where functions of $u$ and $\nabla u$ are contracted with $v$ and $\nabla v$.

Consider the weak form of an arbitrary PDE
\begin{equation}
\begin{array}{c}
\text{find } u \in V \text{ such that for all } v \in V\\
\langle v, u \rangle = \int_{\Omega} v \cdot f_0 \left( u, \nabla u \right) + \nabla v : f_1 \left( u, \nabla u \right) = 0
\end{array}
\label{weak_form}
\end{equation}
where $\cdot$ represents contraction over fields and $:$ represents contraction over fields and spatial dimensions.
The pointwise representation of the weak form given by $f_0$ and $f_1$ does not depend upon discretization choices such as geometry or polynomial degree of the bases.
The corresponding Galerkin system of equations is
\begin{equation}
\sum_e \mathcal{E}^T \left[ \left( \mathbf{B}^e \right)^T \mathbf{W}^e \Lambda \left( f_0 \left( u^e, \nabla u^e \right) \right) + \sum_{i = 0}^{d - 1} \left( \mathbf{D}_i^e \right)^T \mathbf{W}^e \Lambda \left( f_1 \left( u^e, \nabla u^e \right) \right) \right] = 0
\label{galerkin_form}
\end{equation}
where $u^e = \mathbf{B}^e \mathcal{E}^e u$ and $\nabla u^e = \lbrace \mathbf{D}_i^e \mathcal{E}^e u \rbrace_{i = 0}^{d - 1}$.
In this formulation, the element restriction operators and basis operators can represent different element geometries and different degree polynomial bases, providing a flexible description for arbitrary meshes.
Furthermore, this notation can be extended to handle separate fields with different bases, such as with mixed finite element methods.

Dirichlet boundary conditions are represented in the element restriction operation by enforcing the specified values on the constrained nodes.
Neumann or Robin boundary conditions are represented by adding boundary integral terms in the same form as \ref{galerkin_form} with appropriate basis and element restriction operators.
Boundary integrals internal to the domain $\Omega$, such as face integrals in Discontinuous Galerkin methods, can also be represented using additional terms with corresponding bases and element restrictions.

% -- Linearization -------------------------------------------------------------
\subsection{Linearization}

When the PDE \ref{weak_form} is linear, the pointwise functions $f_0$ and $f_1$ are also linear and Krylov subspace methods can be used to solve the Galerkin \ref{galerkin_form}.
When the PDE is non-linear, the Galerkin system of equations \ref{galerkin_form} provides the residual evaluator for a non-linear solver and Jacobian can be represented in a similar fashion as \ref{galerkin_form}, based upon the weak form
\begin{equation}
\langle v, J \left( u \right) w \rangle = \int_{\Omega}
\left[ \begin{array}{c c}
v^T & \left( \nabla v \right)^T
\end{array} \right]
\left[ \begin{array}{c c}
f_{0, 0} & f_{0, 1}\\
f_{1, 0} & f_{1, 1}
\end{array} \right]
\left[ \begin{array}{c c}
w & \nabla w
\end{array} \right]
\label{jacobian_form}
\end{equation}
where $f_{i, 0} = \frac{\partial f_i}{\partial u} \left( u, \nabla u \right)$ and $f_{i, 1} = \frac{\partial f_i}{\partial \nabla u} \left( u, \nabla u \right)$.
If these pointwise functions $f_{i, j}$ are not available analytically, they can be computed via algorithmic differentiation or finite differencing.

With these pointwise functions, we can describe Jacobian-free Newton-Krylov methods, which are used to solve non-linear PDEs.
Jacobian-free Newton-Krylov methods were summarized, with preconditioning strategies, by Knoll and Keyes in \cite{knoll2004jacobian}.

% -- Performance ---------------------------------------------------------------
\subsection{Performance}

To demonstrate the performance benefits of high-order finite elements implemented in a matrix-free fashion, we consider the specific case of the screened Poisson equation, $\nabla^2 u - \alpha^2 u = f$.
In this case, application of the finite element operator for a single element requires $\mathcal{O} \left( P^6 \right)$ matrix entries and $\mathcal{O} \left( P^6 \right)$ floating point operations.
In contrast, application of the matrix-free operator for a single element requires $\mathcal{O} \left( P^3 \right)$ floating point values and $\mathcal{O} \left( P^{d + 1} \right)$ floating point operations.

\begin{figure}
\begin{subfigure}{.495\textwidth}
\includegraphics[width=.99\linewidth]{img/assembledVsMatrixFree}
\caption{FLOPs and Bytes per DoF}
\end{subfigure}
\begin{subfigure}{.495\textwidth}
\includegraphics[width=.99\linewidth]{img/assembledVsMatrixFreeBalance}
\caption{Ratio of Bytes to FLOPs}
\end{subfigure}
\caption{Performance per DoF}
\label{fig:assembledvsmatrixfree}
\end{figure}

As seen in Figure \ref{fig:assembledvsmatrixfree}, balance between bandwidth and FLOPs for matrix-free implementations more closely agrees with current HPC hardware capabilities.

In comparison to generation of simplex meshes, generation of high quality hexahedral meshes is a time intensive process.
However, it is possible to generate meshes comprised predominately of high quality hexahedral elements with initial refinement of a simplex mesh without the costly process of fully converting a simplex mesh into hexahedral elements.
Thus, the performance benefits of high-order matrix-free finite elements can be realized without substantial additional effort in generating a mesh exclusively composed of high quality hexahedral elements.

% ------------------------------------------------------------------------------
% Hyperelasticity
% ------------------------------------------------------------------------------
\section{Hyperelasticity}\label{hyperelasticity}

Although our techniques are applicable to a wide range of problems, we are primarily interested in exploring Neo-Hookean hyperelasticity at finite strain in the incompressible regime.

% Small Strain
% ------------------------------------------------------------------------------
%\subsection{Small Strain}\label{smallstrain}

%The strong form of the static balance of linear momentum at small strain for the three-dimensional linear elasticity problem is given by \cite{hughes2012finite}

%\begin{equation}
%\nabla \cdot \boldsymbol{\sigma} + \boldsymbol{g} = \boldsymbol{0}
%\label{small_strong}
%\end{equation}
%where $\boldsymbol{\sigma}$ and $\boldsymbol{g}$ are stress and forcing functions, respectively.
%We have the weak form
%\begin{equation}
%\int_{\Omega}{ \nabla \boldsymbol{v} \colon \boldsymbol{\sigma}} - \int_{\partial \Omega}{\boldsymbol{v} \cdot \left(\boldsymbol{\sigma} \cdot \hat{\boldsymbol{n}}\right)} - \int_{\Omega}{\boldsymbol{v} \cdot \boldsymbol{g}} = 0
%\label{small_weak}
%\end{equation}
%where $\boldsymbol{\sigma} \cdot \hat{\boldsymbol{n}}|_{\partial \Omega}$ is replaced by an applied force/traction boundary condition.

%The constitutive law (stress-strain relationship) is given by
%\begin{equation}
%\boldsymbol{\sigma} = \lambda \log(1 + \operatorname{trace} \boldsymbol{\epsilon}) \boldsymbol{I} + 2\mu \boldsymbol{\epsilon}
%\label{small_constitutive}
%\end{equation}
%where strain is given by $\boldsymbol{\epsilon} = \dfrac{1}{2}\left(\nabla \boldsymbol{u} + \nabla \boldsymbol{u}^T \right)$ and the Lam{\'e} parameters are given by $\lambda = \frac{E \nu}{(1 + \nu)(1 - 2 \nu)}$ and $\mu = \frac{E}{2(1 + \nu)}$.

%To derive the Newton linearization of the volumetric term,
%\begin{equation}
%\int_{\Omega} \nabla v : d \boldsymbol{\sigma}
%\label{small_linear_weak}
%\end{equation}
%we begin by expressing the derivative,
%\begin{equation}
%d \boldsymbol{\sigma} = \dfrac{\partial \boldsymbol{\sigma}}{\partial \boldsymbol{\epsilon}} \colon d \boldsymbol{\epsilon}
%\label{small_dconstitutive}
%\end{equation}
%where $d \nabla \boldsymbol{u} = \nabla d \boldsymbol{u}$, so $d \boldsymbol{\epsilon} = \dfrac{1}{2}\left( \nabla d \boldsymbol{u} + \nabla d \boldsymbol{u}^T \right)$.
%Therefore,
%\begin{equation}
%d \boldsymbol{\sigma}  = \bar{\lambda} \cdot \operatorname{trace} d \boldsymbol{\epsilon} \cdot \boldsymbol{I} + 2\mu d \boldsymbol{\epsilon}
%\label{small_dconstitutive_final}
%\end{equation}
%where $\bar{\lambda} = \dfrac{\lambda}{1 + \boldsymbol{\epsilon}_v }$ and volumetric strain is given by $\boldsymbol{\epsilon}_v = \sum_i \boldsymbol{\epsilon}_{ii}$.

% Finite Strain ----------------------------------------------------------------
%\subsection{Finite Strain}

In the total Lagrangian approach for the Neo-Hookean hyperelasticity problem, the discrete equations are formulated with respect to the reference configuration; we solve for displacement $u \left( X \right)$ in the reference frame $X$.
Our notation is inspired by \cite{holzapfel2000nonlinear}.

The strong form of the static balance of linear-momentum at finite strain is given by
\begin{equation}
- \nabla_X \cdot \boldsymbol{P} - \rho_0 \boldsymbol{g} = 0
\label{finite_strong}
\end{equation}
where $\nabla_X$ indicates that the gradient is calculated with respect to the reference configuration in the finite strain regime.
$P$ and $\boldsymbol{g}$ are the first Piola-Kirchhoff stress tensor and the prescribed forcing function, respectively and $\rho_0$ is the reference mass density.
The first Piola-Kirchhoff stress tensor is given by
\begin{equation}
\boldsymbol{P} = \boldsymbol{F} \, \boldsymbol{S},
\label{first_pk}
\end{equation}
where $S$ is the second Piola-Kirchhoff stress tensor and $\boldsymbol{F} = \boldsymbol{I} + \nabla_X u$ is the deformation gradient.
$\boldsymbol{S}$ is defined by the constitutive model.

Integrating by parts, we have the weak form
\begin{equation}
\int_{\Omega}{\nabla_X \boldsymbol{v} \colon \boldsymbol{P}} - \int_{\Omega}{\boldsymbol{v} \cdot \rho_0 \boldsymbol{g}} - \int_{\partial \Omega}{\boldsymbol{v} \cdot (\boldsymbol{P} \cdot \hat{\boldsymbol{N}})} = 0
\label{finite_weak}
\end{equation}
where $\boldsymbol{P} \cdot \hat{\boldsymbol{N}}|_{\partial\Omega}$ is replaced by any prescribed force/traction boundary conditions written in terms of the reference configuration.

The Newton linearization of the volumentric term is given by
\begin{equation}
\int_{\Omega}{\nabla_X \boldsymbol{v} : d \boldsymbol{P}} = \int_{\Omega} d \boldsymbol{F} \boldsymbol{S} + \boldsymbol{F} d \boldsymbol{S}
\label{finite_weak_linear}
\end{equation}
were $d \boldsymbol{S}$, as above, depends upon the constitutive model chosen to determine the second Piola-Kirchhoff stress tensor.

Omitting the full derivation for the sake of brevity, we are currently interested in the Neo-Hookean constitutive model.
\begin{equation}
\boldsymbol{S} = \lambda \log \left( \lvert \boldsymbol{F} \rvert \right) \boldsymbol{C}^{-1} + 2 \mu \boldsymbol{C}^{-1} \boldsymbol{E}
\label{constitutive}
\end{equation}
where $\boldsymbol{C} = \boldsymbol{F}^T \boldsymbol{F}$ is the right Cauchy-Green tensor and $\boldsymbol{E} = \frac{1}{2} \left( \boldsymbol{C} - \boldsymbol{I} \right)$ is the Green-Lagrange strain tensor.
The Lam{\'e} parameters are given by $\lambda = \frac{E \nu}{\left( 1 + \nu \right)\left( 1 - 2 \nu \right)}$ and $\mu = \frac{E}{2 \left( 1 + \nu \right)}$.

We therefore have in our linearization
\begin{equation}
d \boldsymbol{S} = \frac{\partial \boldsymbol{S}}{\partial \boldsymbol{E}} : d \boldsymbol{E} = \lambda (\boldsymbol{C}^{-1} : d \boldsymbol{E}) \boldsymbol{C}^{-1} + 2 (\mu - \lambda \log \left( \lvert \boldsymbol{F} \rvert \right)) \boldsymbol{C}^{-1} d \boldsymbol{E} \boldsymbol{C}^{-1}
\label{dconstitutive}
\end{equation}

% ------------------------------------------------------------------------------
% Preconditioning
% ------------------------------------------------------------------------------
\section{Preconditioning}\label{preconditioning}

As discussed in Section \ref{hyperelasticity}, high-order matrix-free finite elements offer performance benefits in comparison to assembled sparse matrix representations.
As is typical with sparse matries, matrix-free formulations require iterative solvers for solve the Galerkin system of equations.
We are primarily interested in Conjugate Gradient (CG), first developed by Hestens and Stiefel \cite{hestenes1952methods}, which is Krylov subspace method.
Krylov subspace methods are a natural fit for matrix-free finite elements, as these methods only require matrix-vector products to populate the Krylov subspace
\begin{equation}
\mathcal{K} \left( r_0, \mathbf{A}, k \right) = \lbrace r_0, \mathbf{A} r_0, \dots, \mathbf{A}^{k - 1} r_0 \rbrace
\label{krylov_space}
\end{equation}
which is used to construct increasingly accurate iterates $x^k$ that approach the true solution $x$.

The iteration count to reach convergence of Krylov subspace methods is based upon condition number of the operator \cite{luenberger1973introduction} and high-order finite element operators have notoriously poor condition numbers \cite{hu1998bounds}.
In this section we discuss preconditioners based upon $p$-type multigrid to control the condition number of high-order finite elements implemented in a matrix-free fashion.
With these preconditioners, we can reduce total iteration count and thus total time to solution for these operators.

Suppose we are solving the linear system given by
\begin{equation}
\mathbf{A} x = b
\label{linear_eqn}
\end{equation}
via a Krylov subspace method.
This linear system may come from the Galerkin system of equations of our PDE of interest or the Jacobian of our PDE of interest.
We can improve the convergence of our Krylov method for this system by solving the preconditioned system
\begin{equation}
\left( \mathbf{M}_L^{-1} \mathbf{A} \mathbf{M}_R^{-1} \right) \left( \mathbf{M}_R x \right) = \mathbf{M}_L^{-1} b
\label{precond_eqn}
\end{equation}
via our Krylov method instead.
We will investigate left preconditioning, where $\mathbf{M}_R = I$ and $\mathbf{M}_L^{-1} \approx \mathbf{A}^{-1}$.
Therefore, we will adopt the notation $\mathbf{M}_L = \mathbf{M}$.

Note that preconditioning CG is more restrictive than other Krylov methods as the CG algorithm requires preconditioners to preserve the symmetric positive definite property of the operator representing the Galerkin system.
Thus, preconditioning methods for CG can be applied to more general Krylov methods, such as generalized minimal residual method (GMRES).

% P-Multigrid ------------------------------------------------------------------
\subsection{P-Multigrid}\label{p-multigrid}

Multigrid methods are popular multi-level techniques that provide resolution independent convergence rates.
$p$-type multigrid, developed by Ronquist and Patera \cite{ronquist1987spectral}, is a natural choice for high-order finite elements on an unstructured mesh and can be implemented with operators represented as in \ref{galerkin_form}.
Ronquist and Patera declared $p$-multigrid \textit{sensibly independent} of number of elements and polynomial degree of the element bases.
Multigrid can be used as an independent solver, but we investigate the use of multigrid as a preconditioner for a Krylov method.

There has been work by Heys, Manteuffel, McCormick, and Olson demonstrating the feasibility of algebraic multigrid (AMG) for high-order finite elements \cite{heys2005algebraic}; however, algebraic multigrid requires assembly of the finite element operator, which defeats the benefits of matrix-free implementation.
There are examples of using $h$-multigrid for matrix-free finite elements in solid mechanics, such as \cite{davydov2019matrix}; however $p$-multigrid offers more flexibility with respect to meshes in comparison to $h$-multigrid as it does not require aggregation of multiple elements into larger elements.

While the theoretical foundation for $p$-multigrid implemented in a matrix-free fashion on unstructured meshes has existed for quite some time, there do not appear to be many examples of these techniques being combined for practical problems.
We are collaborating on a paper implementing these techniques in the context of Neo-Hookean hyperelasticity at finite strain.
This is a new contribution to the solid mechanics community, which typically uses low order finite elements and assembled sparse matrices.
Overall, the use of high-order finite elements with $p$-multigrid is under-explored for solid mechanics problems, especially with high-contrast or nearly incompressible materials.

Application of $p$-multigrid follows the typical multigrid algorithm \ref{multigrid}, such as described by \cite{brandt1982guide}
\begin{algorithm}
\caption{Multigrid Algorithm}
\label{multigrid}
\begin{algorithmic}[1]
\State Compute $x^k$
\State $x^k \gets x^k + \hat{\mathbf{M}}^{-1} \left( b - \mathbf{A} x^k \right)$ \Comment{pre-smooth $m$ times}
\State $r = \mathbf{R} \left( b - \mathbf{A} x^k \right)$ \Comment{restrict the residual}
\State $\mathbf{A}_c e = r$ \Comment{Solve on coarse grid (may involve additional levels)}
\State $x^k \gets x^k + \mathbf{P} e$ \Comment{prolongate error}
\State $x^k \gets x^k + \hat{\mathbf{M}}^{-1} \left( b - \mathbf{A} x^k \right)$ \Comment{post-smooth $m$ times}
\end{algorithmic}
\end{algorithm}
where $\mathbf{P}$ is the grid prolongation operator, $\mathbf{R}$ the grid restriction operator, $\hat{\mathbf{M}}$ a separate preconditioner used for smoothing, and $\mathbf{A}_c$ represents solving the error correction problem on the coarse grid, which may involve recursively applying $p$-multigrid.

For $p$-multigrid with nodal bases, the prolongation operator interpolates using the lower order basis functions to the higher order basis nodes and is defined by
\begin{equation}
\mathbf{P}_{p - 1}^p = \Lambda \left( m_p^{-1} \right) \sum_e \mathcal{E}_p^T \mathbf{B}_{p - 1}^p \mathcal{E}_{p - 1}
\label{mg_prolong}
\end{equation}
where $\mathbf{B}_{p - 1}^p$ interpolates from a basis of degree $p - 1$ to degree $p$ and $m_p = \mathcal{E}_p^T \mathcal{E}_p 1$ counts the multiplicity of shared nodes between elements.
To preserve symmetry and prevent aliasing, the restriction operator is defined as the transpose of the prolongation operator, $\mathbf{R}_{p - 1}^p = \left( \mathbf{P}_{p - 1}^p \right)^T$.
These operators can be implemented matrix-free, in the same fashion as \ref{galerkin_form}.

Even modest order finite elements, such as degree $4$, $p$-multigrid can substantially reduce the size of the global solution vector by a factor of approximately $P^3 / 8$.
Thus, assembly of the finite element operator on the coarse grid, $\mathbf{A}_c$, becomes tractable and direct solvers can be used to solve the coarse problem.
We use AMG for a coarse grid solver, which allows us to leverage the benefits discussed by Heys, Manteuffel, McCormick, and Olson \cite{heys2005algebraic}.

% Smoothers --------------------------------------------------------------------
\subsection{Smoothers}\label{smoothers}

In multigrid preconditioning, the smoother is an important component that helps resolve the error correction on a given multigrid level.
The smoother targets the high-energy components, which corresponds to the larger eigenvalues in the spectrum of the operator.
Below we discuss the more traditional Jacobi and Chebyshev smoothers as well as a proposed domain decomposition based technique.
These smoothers can also be used as preconditioners outside the context of multigrid.

\subsubsection{Jacobi and Chebyshev}

Efficient Jacobi and Chebyshev implementations are important as smoothers for multigrid preconditioners.
As discussed in \cite{adams2003parallel}, the Chebyshev semi-iterative method is a particularly good choice as a smoother for parallel multigrid implementations.
It is easier to provide adequate estimates of the maximal eigenvalue and Chebyshev is not too sensitive to estimation of this parameter.

Currently, we use the Chekyshev semi-iterative method with our current Neo-Hookean hyperelasticity solver.
While Jacobi and Chebyshev techniques are well established, there is some work to be done in providing efficient operator diagonal or block diagonal assembly, especially in the context of matrix-free Jacobians computed via numerical or algorithmic differentiation.

% Domain Decomposition ---------------------------------------------------------
\subsubsection{Domain Decomposition}\label{domaindecomposition}

Domain decomposition methods are another popular class of preconditioners that can provide smoothers for multigrid methods.
Fisher, among others, has used overlapping Schwarz for high-order finite elements or spectral elements with fluid dynamics problems, such as in \cite{fischer1997overlapping} and \cite{fischer2005hybrid}.
However, overlapping Schwarz requires additional memory movement and computation due to the overlap.

Balancing Domain Decomposition by Constraints (BDDC), first developed by Dohrmann \cite{dohrmann2003preconditioner}, is technique for non-overlapping domain decomposition.
In BDDC, the coarse problem is solved on a reduced set of shared nodes between subdomains, using element corners and edges in 3D.
BDDC is closely related to Finite Element Tearing and Interconnecting (FETI), developed by Farhat and Roux \cite{farhat1991method}, and subclasses of these two methods can be shown to be the same method \cite{fragakis2003mosaic}, \cite{klawonn2001feti}, and \cite{rixen1999theoretical}.

For sufficiently high-order elements, we can treat each element as a subdomain.
We partition the degrees of freedoms into two groups, those on the interface $\Gamma$ and those in the interior $I$.
We can therefore formulate the BDDC preconditioner, as seen in \cite{brown2019local}, as
\begin{equation}
\hat{\mathbf{M}}^{-1} = \left( \mathbf{R}_1^T - \mathcal{H} \mathbf{J}_D \right) \hat{\mathbf{A}}^{-1} \left( \mathbf{R}_1 \mathbf{J}_D^T \mathcal{H} \right)
\label{bddc}
\end{equation}
where $\mathcal{H}$ is the direct sum of local operators $\mathcal{H}^{\left( i \right)} = - \left( \mathbf{A}_{I I}^{\left( i \right)} \right)^{-1} \left( A_{\Gamma I}^{\left( i \right)} \right)^T$ that map the jump over subdomain interfaces $J_D$ to subdomain interiors by solving a local Dirichlet problem and giving zero for other values so
\begin{equation}
\left( \mathbf{J}_D^T v \left( x \right) \right)^{\left( i \right)} = \sum_{j \in \mathcal{N}_x} \left( \delta_j \left( x \right) v^{\left( i \right)} \left( x \right) - \delta_i \left( x \right) v^{\left( j \right)} \left( x \right) \right) \forall x \in \Gamma_i
\label{sub_jump}
\end{equation}
with $\delta_i \left( x \right) = 1 / \lvert \mathcal{N}_x \rvert$ and $\mathcal{N}_x$ is the set of indices of subdomains that have $x$ on their boundary.
The function $\delta_i \left( x \right)$ is used to create the scaled injection operator $\mathbf{R}_1$ such that interior values have $1$ and interface values have $\lvert \mathcal{N}_x \rvert$ entries each set to $\delta_i \left( x \right)$.

The operator $\widetilde{\mathbf{A}}^{-1}$ represents a subdomain solver.
This subdomain solver is often a direct method; however, Li and Widlun demonstrated the feasibility of inexact solvers in \cite{li2007use}.

% Subdomain Solvers ------------------------------------------------------------
\subsubsection{Subdomain Solvers}\label{subdomainsolvers}

We are investigating separable approximate inverses based on the Fast Diagonalization Method (FDM) for non-separable problems as inexact subdomain solvers.

Lynch, Rice, and Thomas introduced FDM in \cite{lynch1964direct}.
FDM directly solves separable linear equations based upon tensor products of lower dimension operators.
The screened Poisson operator, $\left( \alpha^2 - \nabla^2 \right) u$, has the Galerkin system of equations
\begin{equation}
\sum_e \mathcal{E}^T \left[ \left( \mathbf{B}^e \right)^T \mathbf{W}^e \Lambda \left( \left( \alpha^2 \right) \mathbf{B}^e \mathcal{E}^e u \right) + \sum_{i = 0}^{d - 1} \left( \mathbf{D}_i^e \right)^T \mathbf{W}^e \Lambda \left( \lbrace \mathbf{D}_i^e \mathcal{E}^e u \rbrace_{i = 0}^{d - 1} \right) \right]
\label{screened_galerkin}
\end{equation}
For a single element, the Galerkin system \ref{screened_galerkin} for the 3D screened Poisson problem can be rewritten as
\begin{equation}
A = \alpha^2 \mathbf{M} + \sum_{i = 0}^{d - 1} \mathbf{K}_i
\label{helmholz_stiffness}
\end{equation}
where $\mathbf{M} = \mathbf{B}^T \mathbf{W} \mathbf{B}$, $\mathbf{K}_i = \mathbf{D}_i^T \mathbf{W} \mathbf{D}_i$, and so on.
In this example, we neglect the terms arising from the coordinate mapping as they can result in a non-separable operator.

These operators $\mathbf{M}$ and $\mathbf{K}$ can be written in terms of the 1D operators, $M = B^T W B$ and $K = D^T W D$, as $\mathbf{M} = M \otimes M \otimes M$, $\mathbf{D}_0 = D \otimes M \otimes M$, and so on.
As $K$ is symmetric and $M$ is symmetric positive definite, we can simultaneously diagonalize $K$ and $M$, yielding $\mathcal{X}^T M \mathcal{X} = I$ and $\mathcal{X}^T K \mathcal{X} = L$.
With these pseudoeigenvalues and pseudoeigenvectors, we can rewrite $A$ as
\begin{equation}
A = \boldsymbol{\mathcal{X}} \left( \alpha^2 \mathbf{I} + \sum_{i = 0}^{d - 1} \mathbf{L}_i \right) \boldsymbol{\mathcal{X}}^T
\label{helmholz_diag}
\end{equation}
with inverse
\begin{equation}
A^{-1} = \boldsymbol{\mathcal{X}}^T \left( \alpha^2 \mathbf{I} + \sum_{i = 0}^{d - 1} \mathbf{L}_i \right)^{-1} \boldsymbol{\mathcal{X}}
\label{helmholz_inv}
\end{equation}
where $\boldsymbol{\mathcal{X}} = \mathcal{X} \otimes \mathcal{X} \otimes \mathcal{X}$, $\mathbf{L}_0 = L \otimes I \otimes I$, and so on.
Notice that if we treat $\boldsymbol{\mathcal{X}}$ as a basis operation, these inverses can be described and implemented matrix-free, as in \ref{galerkin_form}.

With non-separable operators $A$, a suitable choice of $\left( \alpha^2 \mathbf{I} + \sum_{i = 0}^{d - 1} \mathbf{L}_i \right)$ can produce suitable approximate subdomain solvers.
Fisher, Miller, and Tufo demonstrated in \cite{fischer2000overlapping} that while FDM cannot be used for arbitrarily deformed subdomains, defining the diagonalization over a parallelepiped with average dimensions in each coordinate direction is adequate for preconditioning.
For PDEs with arbitrarily deformed subdomains and non-linear pointwise functions $f_0$ and $f_1$, early experiments indicate that a suitable approximate inverse might be constructed by correctly selecting pseudoeigenvalues to use with pseudoeigenvectors from the mass and stiffness matrices given above in \ref{helmholz_stiffness}.
These approximate inverse techniques may be used with other domain decomposition techniques; however, overlapping techniques may require significant additional computation at high-order due to the additional nodes in each subdomain.

% Split Preconditioners --------------------------------------------------------
\subsection{Split Preconditioners}

The preconditioners given above are not appropriate for mixed finite element methods.
In these cases, splitting these PDE by fields and applying different preconditioners to different fields can yield an effective preconditioner.
In this way, the above preconditioners can be composed to handle a wider range of problems.

If the operator $A$ has the decomposition
\begin{equation}
A = \left( \begin{array}{cc}
F & B\\
B^T & C\\
\end{array} \right)
\label{block_form}
\end{equation}
then it can be decomposed via LDU as
\begin{equation}
A = \left( \begin{array}{cc}
I & 0\\
B^T F^{-1} & I\\
\end{array} \right)
\left( \begin{array}{cc}
F & 0\\
0 & -S\\
\end{array} \right)
\left( \begin{array}{cc}
I & F^{-1} B\\
0 & I\\
\end{array} \right)
\label{ldu_form}
\end{equation}
where $S = C + B^T F^{-1} B$ is the Schur complement of $F$ in $A$.
The development of block multi-level preconditioners has been extensively explored \cite{elman2008taxonomy}.

We are collaborating in the development of a solver for Neo-Hookean hyperelasticity at finite strain in the incompressible regime.
This solver will split the displacement and discontinuous pressure fields, applying $p$-multigrid to the displacement fields and block Jacobi to the discontinuous pressure field.
This approach will facilitate solving incompressible hyperelastic problems at large scale.

% ------------------------------------------------------------------------------
% Conclusion
% ------------------------------------------------------------------------------
\section{Conclusion}

We discussed the benefits of high-order matrix-free finite elements for solid mechanics problems.
We highlighted several areas for future improvement in preconditioning for high-order finite element operators implemented in a matrix-free fashion.
$p$-multigrid with matrix-free prolongation, restriction, and smoothing operators is a natural fit for high-order matrix-free finite elements and has proven effective in solid mechanics problems.
While Jacobi and Chebyshev semi-iterative preconditioning is not new, these techniques are important as smoothers for multigrid methods, and there is work to be done on providing efficient operator diagonal or point block diagonal assembly, especially for Jacobians computed via numerical or alogrithmic differentiation.
BDDC is another attractive technique for smoothing multigrid methods, and FDM based matrix-free separable approximate inverses may provide suitable subdomain solvers for BDDC and other domain decomposition techniques with non-linear and non-separable problems.
Neo-Hookean hyperelasticity at finite strain in the incompressible regime will require mixed finite elements with split preconditioning.

% ------------------------------------------------------------------------------
% Acknowledgements
% ------------------------------------------------------------------------------
\section*{Acknowledgments}

This work is supported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S. Department of Energy organizations (Office of Science and the National Nuclear Security Administration) responsible for the planning and preparation of a capable exascale ecosystem, including software, applications, hardware, advanced system engineering and early testbed platforms, in support of the nationâ€™s exascale computing imperative.

\bibliographystyle{siamplain}
\bibliography{references/references}
\end{document}
